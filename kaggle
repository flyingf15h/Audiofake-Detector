{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8130934,"sourceType":"datasetVersion","datasetId":4555568}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git pull","metadata":{"_uuid":"f76302e8-954f-487d-9676-fe249f673d31","_cell_guid":"bd471b6c-3276-4a8c-825f-c6d02a33c1af","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-10T17:56:25.240166Z","iopub.execute_input":"2025-07-10T17:56:25.240939Z","iopub.status.idle":"2025-07-10T17:56:25.573332Z","shell.execute_reply.started":"2025-07-10T17:56:25.240911Z","shell.execute_reply":"2025-07-10T17:56:25.572662Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python train.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:56:27.888214Z","iopub.execute_input":"2025-07-10T17:56:27.888717Z","iopub.status.idle":"2025-07-10T18:48:43.535676Z","shell.execute_reply.started":"2025-07-10T17:56:27.888691Z","shell.execute_reply":"2025-07-10T18:48:43.534665Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom pathlib import Path\nimport torchaudio\nimport numpy as np\nimport pywt\nimport json\n\nclass CachedAudioDataset(Dataset):\n    def __init__(self, cache_dir, chunk_size=16000, augment=False):\n        # cache_dir has npy files and json files\n        self.cache_dir = Path(cache_dir)\n        self.chunk_size = chunk_size\n        self.augment = augment\n\n        metadata_path = self.cache_dir / 'metadata.json'\n        if not metadata_path.exists():\n            raise FileNotFoundError(f\"Metadata JSON not found in {self.cache_dir}\")\n        with open(metadata_path, 'r') as f:\n            self.metadata = json.load(f)  # List of dicts: {'feature_path': str, 'label': int}\n\n    def __len__(self):\n        return len(self.metadata)\n\n    def __getitem__(self, idx):\n        entry = self.metadata[idx]\n        feat_path = self.cache_dir / entry['feature_path']\n        label = entry['label']\n\n        features = np.load(feat_path, allow_pickle=True).item()\n\n        x_raw = torch.tensor(features['raw'], dtype=torch.float32)\n        x_fft = torch.tensor(features['stft'], dtype=torch.float32)\n        x_wav = torch.tensor(features['wav'], dtype=torch.float32)\n\n        if self.augment:\n            x_raw = self._augment(x_raw)\n\n        return x_raw, x_fft, x_wav, torch.tensor(label, dtype=torch.long)\n\n    def _augment(self, x_raw):\n        if torch.rand(1) < 0.3:\n            shift = torch.randint(-1600, 1600, (1,)).item()\n            x_raw = torch.roll(x_raw, shifts=shift, dims=1)\n        if torch.rand(1) < 0.3:\n            scale = torch.empty(1).uniform_(0.8, 1.2).item()\n            x_raw = x_raw * scale\n        if torch.rand(1) < 0.2:\n            noise = torch.randn_like(x_raw) * 0.005\n            x_raw = x_raw + noise\n        return x_raw\n\ndef cache_features(data_dir, oc_dir, sample_rate=16000, chunk_size=16000, overwrite=False):\n    #  Precompute and cache features for audio files in data_dir and save in oc_dir.\n\n    from tqdm import tqdm\n    import json\n\n    data_dir = Path(data_dir)\n    oc_dir = Path(oc_dir)\n    oc_dir.mkdir(parents=True, exist_ok=True)\n\n    metadata = []\n\n    for cls in ['real', 'fake']:\n        cls_dir = data_dir / cls\n        if not cls_dir.exists():\n            print(f\"Warning: Class folder {cls_dir} does not exist, skipping.\")\n            continue\n\n        audio_files = list(cls_dir.glob('*.wav')) + list(cls_dir.glob('*.mp3')) + list(cls_dir.glob('*.flac')) + list(cls_dir.glob('*.m4a'))\n\n        print(f\"Caching {len(audio_files)} {cls} files from {cls_dir}\")\n\n        for audio_path in tqdm(audio_files):\n            cache_filename = f\"{audio_path.stem}_sr{sample_rate}_chunk{chunk_size}.npy\"\n            cache_path = oc_dir / cache_filename\n\n            if cache_path.exists() and not overwrite:\n                metadata.append({'feature_path': cache_filename, 'label': 1 if cls == 'fake' else 0})\n                continue\n\n            # Load audio with torchaudio\n            try:\n                waveform, sr_orig = torchaudio.load(str(audio_path))\n                if sr_orig != sample_rate:\n                    resampler = torchaudio.transforms.Resample(sr_orig, sample_rate)\n                    waveform = resampler(waveform)\n                waveform = waveform.mean(dim=0) \n                waveform = waveform.numpy()\n\n                if len(waveform) < chunk_size:\n                    pad_width = chunk_size - len(waveform)\n                    waveform = np.pad(waveform, (0, pad_width), mode='constant')\n                else:\n                    waveform = waveform[:chunk_size]\n\n                # Normalize waveform\n                wav_mean, wav_std = waveform.mean(), waveform.std()\n                if wav_std < 1e-6:\n                    wav_std = 1.0\n                raw_norm = (waveform - wav_mean) / wav_std\n                raw_norm = np.expand_dims(raw_norm.astype(np.float32), axis=0)  # (1, chunk_size)\n\n                # STFT\n                try:\n                    import librosa\n                    stft = librosa.stft(waveform, n_fft=256, hop_length=128)\n                    mag = np.abs(stft)[:128, :128]\n                    mag_mean, mag_std = mag.mean(), mag.std()\n                    if mag_std < 1e-6:\n                        mag_std = 1.0\n                    stft_norm = (mag - mag_mean) / mag_std\n                    stft_norm = np.expand_dims(stft_norm.astype(np.float32), axis=0)  # (1,128,128)\n                except Exception as e:\n                    print(f\"Failed STFT for {audio_path}: {e}\")\n                    stft_norm = np.zeros((1, 128, 128), dtype=np.float32)\n\n                # Wavelet\n                try:\n                    coeffs = pywt.wavedec(waveform, 'db4', level=4)\n                    cA4 = coeffs[0]\n                    cA4_resized = np.resize(cA4, (64, 128))\n                    wav_mean, wav_std = cA4_resized.mean(), cA4_resized.std()\n                    if wav_std < 1e-6:\n                        wav_std = 1.0\n                    wav_norm = (cA4_resized - wav_mean) / wav_std\n                    wav_norm = np.expand_dims(wav_norm.astype(np.float32), axis=0)  # (1,64,128)\n                except Exception as e:\n                    print(f\"Failed Wavelet for {audio_path}: {e}\")\n                    wav_norm = np.zeros((1, 64, 128), dtype=np.float32)\n\n                # Save dict\n                np.save(cache_path, {'raw': raw_norm, 'stft': stft_norm, 'wav': wav_norm})\n\n                metadata.append({'feature_path': cache_filename, 'label': 1 if cls == 'fake' else 0})\n\n            except Exception as e:\n                print(f\"Failed processing {audio_path}: {e}\")\n\n    # Save metadata JSON\n    with open(oc_dir / 'metadata.json', 'w') as f:\n        json.dump(metadata, f)\n\n    print(f\"Caching complete. Cached features saved to {oc_dir}\")\n    print(f\"Metadata saved to {oc_dir / 'metadata.json'}\")\n\ndef prep_cachedata(cache_dir, test_size=0.2, val_size=0.1, augment_train=True):\n    # Split cached metadata into train/val/test datasets.\n    import json\n    from sklearn.model_selection import train_test_split\n\n    cache_dir = Path(cache_dir)\n    metadata_path = cache_dir / 'metadata.json'\n    with open(metadata_path, 'r') as f:\n        metadata = json.load(f)\n\n    # Extract paths and labels\n    paths = [m['feature_path'] for m in metadata]\n    labels = [m['label'] for m in metadata]\n\n    X_temp, X_test, y_temp, y_test = train_test_split(\n        paths, labels, test_size=test_size, random_state=42, stratify=labels\n    )\n\n    val_fraction = val_size / (1 - test_size)\n    X_train, X_val, y_train, y_val = train_test_split(\n        X_temp, y_temp, test_size=val_fraction, random_state=42, stratify=y_temp\n    )\n\n    # Helper to build dataset from lists\n    def build_ds(paths_list, labels_list, augment):\n        items = [{'feature_path': p, 'label': l} for p, l in zip(paths_list, labels_list)]\n        tmp_dir = cache_dir / ('train' if augment else 'val_test')\n        tmp_dir.mkdir(exist_ok=True)\n        json_path = tmp_dir / 'metadata.json'\n        with open(json_path, 'w') as f:\n            json.dump(items, f)\n        return CachedAudioDataset(tmp_dir, augment=augment)\n\n    train_ds = build_ds(X_train, y_train, augment=True)\n    val_ds = build_ds(X_val, y_val, augment=False)\n    test_ds = build_ds(X_test, y_test, augment=False)\n\n    return train_ds, val_ds, test_ds\n\n\nif __name__ == '__main__':\n    data_dir = \"/kaggle/input/the-fake-or-real-dataset/for-2sec/for-2seconds/training\"\n    cache_dir = \"/kaggle/working/cached_features/training\"\n\n    Path(cache_dir).mkdir(parents=True, exist_ok=True)\n\n    cache_features(data_dir, cache_dir, sample_rate=16000, chunk_size=16000, overwrite=False)\n\n    train_ds, val_ds, test_ds = prep_cachedata(\"/kaggle/working/cached_features/training\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T18:59:49.067169Z","iopub.execute_input":"2025-07-10T18:59:49.067956Z","iopub.status.idle":"2025-07-10T19:03:56.433676Z","shell.execute_reply.started":"2025-07-10T18:59:49.067928Z","shell.execute_reply":"2025-07-10T19:03:56.432896Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!tar -czf /kaggle/working/cached_features.tar.gz -C /kaggle/working/cached_features .","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T19:25:50.714900Z","iopub.execute_input":"2025-07-10T19:25:50.715732Z","iopub.status.idle":"2025-07-10T19:27:37.303484Z","shell.execute_reply.started":"2025-07-10T19:25:50.715704Z","shell.execute_reply":"2025-07-10T19:27:37.302438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!split -b 500M /kaggle/working/cached_features.tar.gz \"cached_features_part_\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T19:47:17.271188Z","iopub.execute_input":"2025-07-10T19:47:17.271874Z","iopub.status.idle":"2025-07-10T19:47:20.154432Z","shell.execute_reply.started":"2025-07-10T19:47:17.271845Z","shell.execute_reply":"2025-07-10T19:47:20.153627Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"import shutil\n\nshutil.rmtree('/kaggle/working/cached_features', ignore_errors=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T19:59:17.953501Z","iopub.execute_input":"2025-07-10T19:59:17.954336Z","iopub.status.idle":"2025-07-10T19:59:18.759320Z","shell.execute_reply.started":"2025-07-10T19:59:17.954307Z","shell.execute_reply":"2025-07-10T19:59:18.758553Z"}},"outputs":[],"execution_count":45}]}